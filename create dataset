import geopandas as gpd
import pandas as pd
import requests
import overpy
from geopy.geocoders import Nominatim
import time
from datetime import datetime
from shapely.geometry import Point
from collections import defaultdict
from datetime import timezone, timedelta

# --- API –∫–ª—é—á–∏ ---

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API ---
geolocator = Nominatim(user_agent="gpx-analyzer")
overpass = overpy.Overpass()
weather_cache = defaultdict(dict)

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

def fetch_gpx_points(url, track_num):
    gpx_file = f"track_{track_num}.gpx"
    with open(gpx_file, "wb") as f:
        f.write(requests.get(url).content)
    return gpd.read_file(gpx_file, layer="track_points")

def get_region(point):
    try:
        loc = geolocator.reverse((point.y, point.x), timeout=10)
        return loc.raw.get("address", {}).get("state", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ") if loc else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    except:
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

def get_location_type(lat, lon, radius=500):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –º–µ—Å—Ç–Ω–æ—Å—Ç–∏ (–≥–æ—Ä–æ–¥, –ø—Ä–∏–≥–æ—Ä–æ–¥, —Å–µ–ª—å—Å–∫–∞—è –º–µ—Å—Ç–Ω–æ—Å—Ç—å, –ø—Ä–∏—Ä–æ–¥–Ω–∞—è –∑–æ–Ω–∞)"""
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–º—É –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—é
        location = geolocator.reverse((lat, lon), timeout=10)
        if location:
            address = location.raw.get('address', {})
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ä–æ–¥—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            if 'city' in address or 'town' in address or 'suburb' in address:
                if 'suburb' in address:
                    return "–ü—Ä–∏–≥–æ—Ä–æ–¥"
                return "–ì–æ—Ä–æ–¥"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ–ª—å—Å–∫—É—é –º–µ—Å—Ç–Ω–æ—Å—Ç—å
            if 'village' in address or 'hamlet' in address or 'county' in address:
                return "–°–µ–ª—å—Å–∫–∞—è –º–µ—Å—Ç–Ω–æ—Å—Ç—å"
        
        # –ï—Å–ª–∏ –ø–æ –∞–¥—Ä–µ—Å—É –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º Overpass –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        result = overpass.query(f"""
        (
            node(around:{radius},{lat},{lon});
            way(around:{radius},{lat},{lon});
            relation(around:{radius},{lat},{lon});
        );
        out tags;
        """)
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–≥–æ–≤ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        urban_features = 0
        natural_features = 0
        
        for elem in result.nodes + result.ways + result.relations:
            tags = elem.tags
            if 'building' in tags or 'highway' in tags or 'amenity' in tags:
                urban_features += 1
            if 'natural' in tags or 'landuse' in tags and tags['landuse'] in ['forest', 'meadow', 'grass']:
                natural_features += 1
        
        if urban_features > 3:
            return "–ì–æ—Ä–æ–¥" if urban_features > 10 else "–ü—Ä–∏–≥–æ—Ä–æ–¥"
        elif natural_features > 2:
            return "–ü—Ä–∏—Ä–æ–¥–Ω–∞—è –∑–æ–Ω–∞"
        else:
            return "–°–µ–ª—å—Å–∫–∞—è –º–µ—Å—Ç–Ω–æ—Å—Ç—å"
            
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –º–µ—Å—Ç–Ω–æ—Å—Ç–∏: {e}")
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

def get_surroundings(lat, lon, radius=500):
    try:
        result = overpass.query(f"""
        (
            node(around:{radius},{lat},{lon});
            way(around:{radius},{lat},{lon});
            relation(around:{radius},{lat},{lon});
        );
        out tags;
        """)
        tags = {
            tag + ":" + elem.tags[tag]
            for elem in result.nodes + result.ways + result.relations
            for tag in ["natural", "landuse", "amenity", "leisure", "building"]
            if tag in elem.tags
        }
        return ", ".join(sorted(tags)) if tags else "–Ω–∏—á–µ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ"
    except:
        return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

def estimate_step_frequency(gdf):
    if "time" not in gdf.columns:
        return None
    gdf["time"] = pd.to_datetime(gdf["time"], errors="coerce")
    if gdf["time"].isnull().all():
        return None
    freq = gdf.groupby(gdf["time"].dt.floor("min")).size().mean()
    return round(freq, 2)

def round_to_hour(dt):
    return dt.replace(minute=0, second=0, microsecond=0)

def get_temperature(lat, lon, time_point):
    if pd.isnull(time_point):
        return "‚Äî"

    dt_hour = round_to_hour(time_point)
    dt_iso = dt_hour.replace(tzinfo=timezone.utc).isoformat().replace("+00:00", "Z")

    hour_key = dt_hour.isoformat()
    coord_key = (round(lat, 3), round(lon, 3))

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
    if hour_key in weather_cache[coord_key]:
        return weather_cache[coord_key][hour_key]

    try:
        url = (
            f"https://archive-api.open-meteo.com/v1/era5?"
            f"latitude={lat}&longitude={lon}"
            f"&start_date={dt_hour.date()}&end_date={dt_hour.date()}"
            f"&hourly=temperature_2m&timezone=UTC"
        )
        resp = requests.get(url)
        data = resp.json()

        if "hourly" not in data:
            print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–æ–≥–æ–¥–µ:", data)
            return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

        times = data["hourly"]["time"]
        temps = data["hourly"]["temperature_2m"]

        # –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (¬±1 —á–∞—Å)
        dt_target = dt_hour
        closest_temp = "‚Äî"
        min_diff = timedelta(hours=1, minutes=1)

        for t_str, temp_val in zip(times, temps):
            t = pd.to_datetime(t_str).replace(tzinfo=timezone.utc)
            diff = abs(t - dt_target)
            if diff < min_diff:
                min_diff = diff
                closest_temp = temp_val

        weather_cache[coord_key][hour_key] = closest_temp
        time.sleep(0.5)
        return closest_temp

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã Open-Meteo: {e}")
        return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

def haversine(p1, p2):
    from math import radians, sin, cos, sqrt, atan2
    R = 6371000  # —Ä–∞–¥–∏—É—Å –ó–µ–º–ª–∏ –≤ –º–µ—Ç—Ä–∞—Ö
    lat1, lon1 = radians(p1.y), radians(p1.x)
    lat2, lon2 = radians(p2.y), radians(p2.x)
    dlat, dlon = lat2 - lat1, lon2 - lon1

    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R * c

def process_track(url, track_num):
    print(f"\nüìç –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–µ–∫–∞ {track_num}")
    gdf = fetch_gpx_points(url, track_num)
    if gdf.empty:
        print("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ç—Ä–µ–∫")
        return

    pd.DataFrame()

    gdf["time"] = pd.to_datetime(gdf["time"], errors="coerce")
    gdf = gdf.to_crs(epsg=4326)  # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º WGS84

    step_freq = estimate_step_frequency(gdf)
    region = get_region(gdf.geometry.iloc[0])
    last_env_point = None
    last_env_type = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    last_env_desc = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    records = []
    for _, row in gdf.iterrows():
        pt = row.geometry
        lat, lon = pt.y, pt.x
        time_point = row.get("time")
        date = time_point.date() if pd.notnull(time_point) else "‚Äî"
        ele = row.get("ele")

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ
        if last_env_point is None or haversine(pt, last_env_point) >= 500:
            last_env_type = get_location_type(lat, lon)
            last_env_desc = get_surroundings(lat, lon)
            last_env_point = pt
            time.sleep(1.0)

        # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ ‚Äî —Ä–∞–∑ –≤ —á–∞—Å
        temp = get_temperature(lat, lon, time_point) if pd.notnull(time_point) else "‚Äî"

        records.append({
            "–¢—Ä–µ–∫": track_num,
            "–î–∞—Ç–∞": date,
            "–†–µ–≥–∏–æ–Ω": region,
            "–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã": (lat, lon),
            "–ß–∞—Å—Ç–æ—Ç–∞ —à–∞–≥–æ–≤": step_freq,
            "–í—ã—Å–æ—Ç–∞": ele,
            "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞": temp,
            "–ú–µ—Å—Ç–Ω–æ—Å—Ç—å": last_env_type,
            "–û–±—ä–µ–∫—Ç—ã –≤–æ–∫—Ä—É–≥": last_env_desc
        })

    return pd.DataFrame(records)

# --- –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ ---

if __name__ == "__main__":
    urls = [
        "https://www.openstreetmap.org/traces/11951791/data",
        "https://www.openstreetmap.org/traces/11951772/data",
        "https://www.openstreetmap.org/traces/11952070/data"
    ]

    result = pd.concat([process_track(url, i+1) for i, url in enumerate(urls)], ignore_index=True)
    result.to_csv("enriched_track_points2.csv", index=False)
    print("\n‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'enriched_track_points.csv'")
